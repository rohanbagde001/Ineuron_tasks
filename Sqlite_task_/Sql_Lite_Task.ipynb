{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3d0565e0",
   "metadata": {},
   "source": [
    "\"\"\"Task for today : dataset - https://archive.ics.uci.edu/ml/datasets/Bag+of+Words\n",
    "\n",
    "q1 = try to find out a count of each and every word in a respective file return a list of tuple with word and its respective count \n",
    "   sample example -  [('sudh', 6 ) , ('kumar',3)]\n",
    "q2 = try to perform a reduce operation to get a count of all the word starting with same alphabet\n",
    "    sample examle = [(a,56) , (b,34),...........]\n",
    "q3 = Try to filter out all the words from dataset . \n",
    "\n",
    ".001.abstract = abstract\n",
    "=.002 = delete\n",
    "q4 = create a tuple set of all the records avaialble in all the five file and then store it in sqllite DB . \n",
    "(aah,>=,354,fdsf,wer)\n",
    "\n",
    "Top 10 will be able to get kids neuron \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "20ced826",
   "metadata": {},
   "source": [
    "Title:  Bag of Words Data Set\n",
    "\n",
    "Abstract: This data set contains five text collections in the form of bags-of-words.\n",
    "\n",
    "-----------------------------------------------------\t\n",
    "\n",
    "Data Set Characteristics: Text\n",
    "Number of Instances: 8000000\n",
    "Area: N/A\n",
    "Attribute Characteristics: Integer\n",
    "Number of Attributes: 100000\n",
    "Date Donated: 2008-03-12\n",
    "Associated Tasks: Clustering\n",
    "Missing Values? N/A\n",
    "\n",
    "-----------------------------------------------------\t\t\n",
    "\n",
    "Source:\n",
    "\n",
    "David Newman\n",
    "newman '@' uci.edu\n",
    "University of California, Irvine\n",
    "\n",
    "-----------------------------------------------------\t\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "For each text collection, D is the number of documents, W is the\n",
    "number of words in the vocabulary, and N is the total number of words\n",
    "in the collection (below, NNZ is the number of nonzero counts in the\n",
    "bag-of-words). After tokenization and removal of stopwords, the\n",
    "vocabulary of unique words was truncated by only keeping words that\n",
    "occurred more than ten times. Individual document names (i.e. a\n",
    "identifier for each docID) are not provided for copyright reasons.\n",
    "\n",
    "These data sets have no class labels, and for copyright reasons no\n",
    "filenames or other document-level metadata.  These data sets are ideal\n",
    "for clustering and topic modeling experiments.\n",
    "\n",
    "For each text collection we provide docword.*.txt (the bag of words\n",
    "file in sparse format) and vocab.*.txt (the vocab file).\n",
    "\n",
    "Enron Emails:\n",
    "orig source: www.cs.cmu.edu/~enron\n",
    "D=39861\n",
    "W=28102\n",
    "N=6,400,000 (approx)\n",
    "\n",
    "NIPS full papers:\n",
    "orig source: books.nips.cc\n",
    "D=1500\n",
    "W=12419\n",
    "N=1,900,000 (approx)\n",
    "\n",
    "KOS blog entries:\n",
    "orig source: dailykos.com\n",
    "D=3430\n",
    "W=6906\n",
    "N=467714\n",
    "\n",
    "NYTimes news articles:\n",
    "orig source: ldc.upenn.edu\n",
    "D=300000\n",
    "W=102660\n",
    "N=100,000,000 (approx)\n",
    "\n",
    "PubMed abstracts:\n",
    "orig source: www.pubmed.gov\n",
    "D=8200000\n",
    "W=141043\n",
    "N=730,000,000 (approx)\n",
    "\n",
    "\n",
    "-----------------------------------------------------\t\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "The format of the docword.*.txt file is 3 header lines, followed by\n",
    "NNZ triples:\n",
    "---\n",
    "D\n",
    "W\n",
    "NNZ\n",
    "docID wordID count\n",
    "docID wordID count\n",
    "docID wordID count\n",
    "docID wordID count\n",
    "...\n",
    "docID wordID count\n",
    "docID wordID count\n",
    "docID wordID count\n",
    "---\n",
    "\n",
    "The format of the vocab.*.txt file is line contains wordID=n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f3f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "\n",
    "log.basicConfig(filename='sqlite_task.log',\n",
    "               filemode='a',\n",
    "               level=log.INFO,\n",
    "               format='%(asctime)s %(levelname)s-%(message)s',\n",
    "               datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# creating logger object\n",
    "\n",
    "logger = log.getLogger()\n",
    "logger.setLevel(log.DEBUG)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ad0175b",
   "metadata": {},
   "source": [
    "q1 = try to find out a count of each and every word in a respective file return a list of tuple with word and its respective count \n",
    "       sample example -  [('sudh', 6 ) , ('kumar',3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f21b6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def wordCount(*args):\n",
    "    \"\"\"\n",
    "    wordCount(file1, file2, ... filen)\n",
    "    wordCount(*args)\n",
    "\n",
    "    This function take file(s) as argument and return word with occurence count.\n",
    "\n",
    "    :param:\n",
    "        *args: file(s).\n",
    "    :return: ('word', count(word)) : list(tuples)\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    \n",
    "    try:\n",
    "        for file in args:\n",
    "            with open(file, 'r', encoding=\"utf8\") as f:\n",
    "                data = csv.reader(f)\n",
    "                for row_data in data:\n",
    "                    words.append(row_data[0])\n",
    "    except Exception as e:\n",
    "        logger.error('Error in reading files: ' + str(e))\n",
    "    else:\n",
    "        word_count = []\n",
    "        unique_words = list(set(words))\n",
    "        unique_words.sort()\n",
    "\n",
    "        for i in unique_words:\n",
    "            word_count.append((i, words.count(i)))\n",
    "            #yield (i, words.count(i))\n",
    "        logger.info('Word count for records: ' +  str(len(word_count)) + ' from ' + str(len(args)) + 'Datasets')\n",
    "        \n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0de2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = wordCount('vocab.enron.txt', 'vocab.kos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9193f3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aaa', 1), ('aaas', 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1[0:2]   # fetching top 2 data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b6bdba5",
   "metadata": {},
   "source": [
    "Task 2:\n",
    "q2 = try to perform a reduce operation to get a count of all the word starting with same alphabet\n",
    "sample examle = [(a,56) , (b,34),...........]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9280b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def wordCount_reduce(*args):\n",
    "    \"\"\"\n",
    "    wordCount_reduce(file1, file2, ... filen)\n",
    "    wordCount_reduce(*args)\n",
    "\n",
    "    This function take file(s) as argument and return alphabets with occurence count.\n",
    "\n",
    "    :param:\n",
    "        *args: file(s).\n",
    "    :return: ('alphabets', count(alphabets)) : list(tuples)\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    \n",
    "    try:\n",
    "        for file in args:\n",
    "            with open(file, 'r', encoding=\"utf8\") as f:\n",
    "                data = csv.reader(f)\n",
    "                for row_data in data:\n",
    "                    if row_data[0][0] >= 'a' and row_data[0][0] <= 'z' or row_data[0][0] >= 'A' and row_data[0][0] <= 'Z':\n",
    "                        words.append(row_data[0][0])\n",
    "                        \n",
    "    except Exception as e:\n",
    "        logger.error('Error in reading files: ' + str(e))\n",
    "    \n",
    "    else:\n",
    "        word_count = []\n",
    "        unique_words = list(set(words))\n",
    "        unique_words.sort()\n",
    "\n",
    "\n",
    "        for i in unique_words:\n",
    "            word_count.append((i, words.count(i)))\n",
    "        \n",
    "        logger.info('Data record count : ' +  str(len(word_count)) + ' from ' + str(len(args)) + 'Datasets')\n",
    "        \n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53ac715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 12501),\n",
       " ('b', 7046),\n",
       " ('c', 15155),\n",
       " ('d', 8388),\n",
       " ('e', 7143),\n",
       " ('f', 5642),\n",
       " ('g', 5150),\n",
       " ('h', 7418),\n",
       " ('i', 7097),\n",
       " ('j', 933),\n",
       " ('k', 1855),\n",
       " ('l', 5716),\n",
       " ('m', 10734),\n",
       " ('n', 7647),\n",
       " ('o', 4026),\n",
       " ('p', 15247),\n",
       " ('q', 634),\n",
       " ('r', 7620),\n",
       " ('s', 13603),\n",
       " ('t', 8447),\n",
       " ('u', 2908),\n",
       " ('v', 2784),\n",
       " ('w', 2289),\n",
       " ('x', 425),\n",
       " ('y', 412),\n",
       " ('z', 477)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount_reduce('vocab.enron.txt', 'vocab.pubmed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffaf8ca",
   "metadata": {},
   "source": [
    "Task 3:\n",
    "q3 = Try to filter out all the words from dataset .\n",
    ".001.abstract = abstract =.002 = delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5693f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def filter_word(*args):\n",
    "    \"\"\"\n",
    "    filter_word(file1, file2, ... filen)\n",
    "    filter_word(*args)\n",
    "\n",
    "    This function take file(s) as argument extract only the letters and return  as list.\n",
    "\n",
    "    :param:\n",
    "        *args: file(s).\n",
    "    :return: ('characters') : list(strings)\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    \n",
    "    try:\n",
    "        for file in args:\n",
    "            with open(file, 'r', encoding=\"utf8\") as f:\n",
    "                data = csv.reader(f)\n",
    "                for row_data in data:\n",
    "                    current_word = \"\"\n",
    "                    for char in row_data[0]:\n",
    "                        if char >= 'a' and char <= 'z' or char[0][0] >= 'A' and char[0][0] <= 'Z':\n",
    "                            current_word += char\n",
    "                    words.append(current_word)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error('Error in reading files: ' + str(e))\n",
    "        \n",
    "    else:\n",
    "        alpha = []\n",
    "        unique_words = list(set(words))\n",
    "        unique_words.sort()\n",
    "\n",
    "\n",
    "        for i in unique_words:\n",
    "             #yield (i)\n",
    "            if len(i) > 0:\n",
    "                alpha.append(i)\n",
    "                \n",
    "        logger.info('Total filter records: ' +  str(len(alpha)) + ' from ' + str(len(args)) + 'Datasets')\n",
    "        \n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008c1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words = filter_word('vocab.pubmed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ad8a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaad',\n",
       " 'aaamyloidosis',\n",
       " 'aaar',\n",
       " 'aaas',\n",
       " 'aab',\n",
       " 'aabb']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b70743b6",
   "metadata": {},
   "source": [
    "Task 4:\n",
    "q4 = create a tuple set of all the records avaialble in all the five file and then store it in sqllite DB .\n",
    "(aah,>=,354,fdsf,wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b426c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def task4(*args):\n",
    "    \"\"\"\n",
    "    task4(file1, file2, ... filen)\n",
    "    task4(*args)\n",
    "\n",
    "    This function take file(s) as argument and return list of list.\n",
    "\n",
    "    :param:\n",
    "        *args: file(s).\n",
    "    :return: ('string') : list(strings)\n",
    "    \"\"\"\n",
    "    combine_words = []\n",
    "    try:\n",
    "        for file in args:\n",
    "            with open(file, 'r', encoding=\"utf8\") as f:\n",
    "                data = csv.reader(f)\n",
    "                words = []\n",
    "                for row_data in data:\n",
    "                    words.append(row_data[0])\n",
    "                combine_words.append(words)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error('Error in reading files: ' + str(e))\n",
    "    else:\n",
    "        logger.info('Success Return of list of list')\n",
    "                \n",
    "        return combine_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad97485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = task4('vocab.enron.txt', 'vocab.kos.txt', 'vocab.nips.txt', 'vocab.nytimes.txt', 'vocab.pubmed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be56c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = file[0]\n",
    "f2 = file[1]\n",
    "f3 = file[2]\n",
    "f4 = file[3]\n",
    "f5 = file[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e041e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_zip_list = list(zip(f1, f2, f3, f4, f5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1115d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aaa', 'aarp', 'a2i', 'aah', '>='),\n",
       " ('aaas', 'abandon', 'aaa', 'aahed', '>>'),\n",
       " ('aactive', 'abandoned', 'aaai', 'aaron', '>>>'),\n",
       " ('aadvantage', 'abandoning', 'aapo', 'aback', '>/='),\n",
       " ('aaker', 'abb', 'aat', 'abacus', '->'),\n",
       " ('aap', 'abc', 'aazhang', 'abajo', '--'),\n",
       " ('aapg', 'abcs', 'abandonment', 'abalone', '-->'),\n",
       " ('aaron', 'abdullah', 'abbott', 'abandon', '-/-'),\n",
       " ('aarp', 'ability', 'abbreviated', 'abandoned', '-/+'),\n",
       " ('aas', 'aboard', 'abcde', 'abandoning', '/-')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_zip_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af532cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLite Database and Table Creation\n",
    "Dumping the above data into the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e6d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "try:\n",
    "    db = sqlite3.connect('vocab_database.db')\n",
    "    logger.info('Database Created: ' +  str(db))\n",
    "    cursor = db.cursor()\n",
    "    query = \"CREATE TABLE main_table(file1 text, file2 text, file3 text, file4 text, file5 text)\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    record_count = 0 \n",
    "    for record in final_zip_list:\n",
    "        query = \"INSERT INTO main_table VALUES {}\".format(tuple(record))\n",
    "        cursor.execute(query)\n",
    "        record_count += 1\n",
    "        \n",
    "    db.commit()\n",
    "    \n",
    "    logger.info('Total records inserted: ' +  str(record_count))\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error('Error: ' + str(e))\n",
    "finally:\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "449bc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect('vocab_database.db')\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f74ef45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aaa', 'aarp', 'a2i', 'aah', '>='),\n",
       " ('aaas', 'abandon', 'aaa', 'aahed', '>>'),\n",
       " ('aactive', 'abandoned', 'aaai', 'aaron', '>>>'),\n",
       " ('aadvantage', 'abandoning', 'aapo', 'aback', '>/='),\n",
       " ('aaker', 'abb', 'aat', 'abacus', '->'),\n",
       " ('aap', 'abc', 'aazhang', 'abajo', '--'),\n",
       " ('aapg', 'abcs', 'abandonment', 'abalone', '-->'),\n",
       " ('aaron', 'abdullah', 'abbott', 'abandon', '-/-'),\n",
       " ('aarp', 'ability', 'abbreviated', 'abandoned', '-/+'),\n",
       " ('aas', 'aboard', 'abcde', 'abandoning', '/-'),\n",
       " ('aau', 'abortion', 'abe', 'abandonment', '/+-'),\n",
       " ('ab1890', 'abortions', 'abeles', 'abandono', '..'),\n",
       " ('ab1x', 'abraham', 'abi', 'abarnard', '...'),\n",
       " ('ab31x', 'abrams', 'abilistic', 'abashed', '+-'),\n",
       " ('aba', 'abroad', 'abilities', 'abate', '+/'),\n",
       " ('abacus', 'absence', 'ability', 'abated', '+/--'),\n",
       " ('abag', 'absent', 'abl', 'abatement', '+/?'),\n",
       " ('abalone', 'absentee', 'able', 'abating', '+/+'),\n",
       " ('abandon', 'absolute', 'ables', 'abbey', '++'),\n",
       " ('abandoned', 'absolutely', 'ablex', 'abbot', '+++')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cursor.execute(\"select * from main_table limit 20\")\n",
    "[i for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
